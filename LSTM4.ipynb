{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MacroHFT dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset shape: (525600, 71)\n",
       "Available columns: ['timestamp' 'ask1_price' 'ask1_size' 'bid1_price' 'bid1_size'\n",
       " 'ask2_price' 'ask2_size' 'bid2_price' 'bid2_size' 'ask3_price'\n",
       " 'ask3_size' 'bid3_price' 'bid3_size' 'ask4_price' 'ask4_size'\n",
       " 'bid4_price' 'bid4_size' 'ask5_price' 'ask5_size' 'bid5_price'\n",
       " 'bid5_size' 'volume' 'bid1_size_n' 'bid2_size_n' 'bid3_size_n'\n",
       " 'bid4_size_n' 'bid5_size_n' 'ask1_size_n' 'ask2_size_n' 'ask3_size_n'\n",
       " 'ask4_size_n' 'ask5_size_n' 'wap_1' 'wap_2' 'wap_balance' 'buy_spread'\n",
       " 'sell_spread' 'buy_volume' 'sell_volume' 'volume_imbalance'\n",
       " 'price_spread' 'sell_vwap' 'buy_vwap' 'log_return_bid1_price'\n",
       " 'log_return_bid2_price' 'log_return_ask1_price' 'log_return_ask2_price'\n",
       " 'log_return_wap_1' 'log_return_wap_2' 'ask1_price_trend_60'\n",
       " 'bid1_price_trend_60' 'buy_spread_trend_60' 'sell_spread_trend_60'\n",
       " 'wap_1_trend_60' 'wap_2_trend_60' 'buy_vwap_trend_60'\n",
       " 'sell_vwap_trend_60' 'volume_trend_60' 'open' 'high' 'low' 'close' 'kmid'\n",
       " 'klen' 'kmid2' 'kup' 'kup2' 'klow' 'klow2' 'ksft' 'ksft2']\n",
       "Sample data:\n",
       "             timestamp   ask1_price  ask1_size  ...     klow2  ksft     ksft2\n",
       "0 2022-02-01 00:00:00  2684.308500  18.342238  ...  0.057674 -4.18 -0.831303\n",
       "1 2022-02-01 00:01:00  2679.292333   9.461557  ...  0.074827 -6.21 -0.815220\n",
       "2 2022-02-01 00:02:00  2677.534833   8.243908  ...  0.236068  8.33  0.862476\n",
       "3 2022-02-01 00:03:00  2685.595167  14.569968  ...  0.109220 -1.43 -0.205506\n",
       "4 2022-02-01 00:04:00  2684.818500   3.575345  ...  0.380157  2.05  0.585956\n",
       "\n",
       "[5 rows x 71 columns]\n",
       "Missing values per column:\n",
       " Series([], dtype: int64)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_feather(\"data_1/ETHUSDT/df_train.feather\")\n",
    "\n",
    "# Analyze the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Available columns:\", df.columns.values)\n",
    "print(\"Sample data:\\n\", df.head())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values[missing_values > 0])\n",
    "\n",
    "# Handle missing values if any\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    df = df.fillna(df.median())\n",
    "\n",
    "# Visualize the target variable (price_spread)\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df['price_spread'].values[:200])\n",
    "plt.title('Price Spread (Target Variable) - First 200 Data Points')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Price Spread')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Show the distribution of the target variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['price_spread'], bins=50)\n",
    "plt.title('Distribution of price_spread')\n",
    "plt.xlabel('price_spread')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Show autocorrelation of the target variable\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "autocorrelation_plot(df['price_spread'].values[:1000])\n",
    "plt.title('Autocorrelation of price_spread')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Correlations with price_spread:\n",
       " price_spread            1.000000\n",
       "wap_balance             0.447740\n",
       "klen                    0.421304\n",
       "kup                     0.310378\n",
       "sell_spread_trend_60    0.293830\n",
       "sell_spread             0.287040\n",
       "buy_spread_trend_60     0.281661\n",
       "klow                    0.276573\n",
       "buy_spread              0.260797\n",
       "ask1_size_n             0.166287\n",
       "bid1_size_n             0.163629\n",
       "ask5_size_n             0.162290\n",
       "bid3_size_n             0.161270\n",
       "ask4_size_n             0.160270\n",
       "ask3_size_n             0.159779\n",
       "Name: price_spread, dtype: float64\n",
       "Selected features: ['log_return_bid1_price', 'ask4_size_n', 'kup2', 'kup', 'log_return_ask2_price', 'klow2', 'ask1_size_n', 'ask3_size_n', 'bid1_size_n', 'bid3_size_n']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze correlations to select features most relevant to price_spread\n",
    "correlation_with_target = df.corr()['price_spread'].abs().sort_values(ascending=False)\n",
    "print(\"Correlations with price_spread:\\n\", correlation_with_target.head(15))\n",
    "\n",
    "# Select top 10 features (excluding the target itself)\n",
    "selected_features = [\n",
    "    'log_return_bid1_price',  # Highest correlation with price_spread\n",
    "    'ask4_size_n',\n",
    "    'kup2',\n",
    "    'kup',\n",
    "    'log_return_ask2_price',\n",
    "    'klow2',\n",
    "    'ask1_size_n',\n",
    "    'ask3_size_n',\n",
    "    'bid1_size_n',\n",
    "    'bid3_size_n'\n",
    "]\n",
    "target_column = 'price_spread'\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Extract features and target\n",
    "X = df[selected_features].values\n",
    "y = df[target_column].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize the data\n",
    "X_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "X_scaled = X_scaler.fit_transform(X)\n",
    "y_scaled = y_scaler.fit_transform(y)\n",
    "\n",
    "# Show the distribution of normalized target\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(y_scaled, bins=50)\n",
    "plt.title('Distribution of Target Values (price_spread)')\n",
    "plt.xlabel('Scaled price_spread')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training data shape: X=(420480, 10), y=(420480, 1)\n",
       "Testing data shape: X=(105120, 10), y=(105120, 1)\n",
       "Training sequences shape: X=(420450, 30, 10), y=(420450, 1)\n",
       "Testing sequences shape: X=(105090, 30, 10), y=(105090, 1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "train_size = int(len(X_scaled) * 0.8)\n",
    "X_train = X_scaled[:train_size]\n",
    "y_train = y_scaled[:train_size]\n",
    "X_test = X_scaled[train_size:]\n",
    "y_test = y_scaled[train_size:]\n",
    "\n",
    "print(f\"Training data shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Testing data shape: X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# Create sequences for LSTM\n",
    "def create_sequences(x, y, time_steps=30):\n",
    "    \"\"\"\n",
    "    Create sequences of data suitable for LSTM training\n",
    "    Args:\n",
    "        x: Features array (samples × features)\n",
    "        y: Target array (samples × 1)\n",
    "        time_steps: Number of time steps to look back\n",
    "    \n",
    "    Returns:\n",
    "        X_seq: Sequence of features (samples × time_steps × features)\n",
    "        y_seq: Target values (samples × 1)\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(x) - time_steps):\n",
    "        X_seq.append(x[i:(i + time_steps)])\n",
    "        y_seq.append(y[i + time_steps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Create sequences\n",
    "time_steps = 30  # Look back 30 time steps\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, time_steps)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, time_steps)\n",
    "\n",
    "print(f\"Training sequences shape: X={X_train_seq.shape}, y={y_train_seq.shape}\")\n",
    "print(f\"Testing sequences shape: X={X_test_seq.shape}, y={y_test_seq.shape}\")\n",
    "\n",
    "# Create PyTorch datasets and loaders\n",
    "batch_size = 64\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_seq)\n",
    "y_train_tensor = torch.FloatTensor(y_train_seq)\n",
    "X_test_tensor = torch.FloatTensor(X_test_seq)\n",
    "y_test_tensor = torch.FloatTensor(y_test_seq)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaLSTM(\n",
       "  (lstm): LSTM(10, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class VanillaLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super(VanillaLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device) \n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Model parameters\n",
    "input_size = len(selected_features)  # Number of features\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "# Create the model\n",
    "model = VanillaLSTM(input_size, hidden_size, output_size)\n",
    "print(model)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Using device: cpu\n",
       "Epoch [1/100], Train Loss: 0.000042, Test Loss: 0.000019\n",
       "Epoch [2/100], Train Loss: 0.000039, Test Loss: 0.000018\n",
       "Epoch [3/100], Train Loss: 0.000038, Test Loss: 0.000020\n",
       "Epoch [4/100], Train Loss: 0.000037, Test Loss: 0.000017\n",
       "Epoch [5/100], Train Loss: 0.000037, Test Loss: 0.000017\n",
       "Traceback (most recent call last):\n",
       "  File \"/Users/lehoangsang/.vscode/extensions/ms-python.python-2025.2.0-darwin-arm64/python_files/python_server.py\", line 133, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"<string>\", line 95, in <module>\n",
       "  File \"<string>\", line 30, in train_model\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
       "    return self._call_impl(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
       "    return forward_call(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"<string>\", line 15, in forward\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
       "    return self._call_impl(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
       "    return forward_call(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/rnn.py\", line 917, in forward\n",
       "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "KeyboardInterrupt\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training function with early stopping\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=100, early_stopping_patience=10):\n",
    "    # Check if GPU is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Early stopping variables\n",
    "    min_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # Move data to device\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                # Move data to device\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.6f}, '\n",
    "              f'Test Loss: {avg_test_loss:.6f}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_test_loss < min_val_loss:\n",
    "            min_val_loss = avg_test_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "    \n",
    "    # Load the best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Plot the loss curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(test_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return model, train_losses, test_losses\n",
    "\n",
    "# Train the model\n",
    "trained_model, train_losses, test_losses = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs=100,\n",
    "    early_stopping_patience=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean Squared Error (MSE): 0.000000\n",
       "Root Mean Squared Error (RMSE): 0.000010\n",
       "Mean Absolute Error (MAE): 0.000003\n",
       "R² Score: -0.012692\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test_tensor, y_test_tensor, y_scaler):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Check if GPU is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        y_pred_scaled = model(X_test_tensor).cpu().numpy()\n",
    "    \n",
    "    # Inverse transform to get actual values\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "    y_actual = y_scaler.inverse_transform(y_test_tensor.numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_actual, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "    \n",
    "    print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.6f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.6f}\")\n",
    "    print(f\"R² Score: {r2:.6f}\")\n",
    "    \n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(y_actual[:200], label='Actual')\n",
    "    plt.plot(y_pred[:200], label='Predicted')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Price Spread')\n",
    "    plt.title('Actual vs Predicted Price Spread - First 200 Predictions')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the distribution of prediction errors\n",
    "    errors = y_actual - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(errors, bins=50)\n",
    "    plt.xlabel('Prediction Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Prediction Errors')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred, y_actual, mse, rmse, mae, r2\n",
    "\n",
    "# Evaluate the trained model\n",
    "y_pred, y_actual, mse, rmse, mae, r2 = evaluate_model(trained_model, X_test_tensor, y_test_tensor, y_scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"/Users/lehoangsang/.vscode/extensions/ms-python.python-2025.2.0-darwin-arm64/python_files/python_server.py\", line 133, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"<string>\", line 54, in <module>\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/pyplot.py\", line 612, in show\n",
       "    return _get_backend_mod().show(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/backend_bases.py\", line 3553, in show\n",
       "    cls.mainloop()\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/backends/backend_macosx.py\", line 178, in start_main_loop\n",
       "    with _allow_interrupt_macos():\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
       "    next(self.gen)\n",
       "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/backend_bases.py\", line 1672, in _allow_interrupt\n",
       "    old_sigint_handler(*handler_args)\n",
       "KeyboardInterrupt\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to make predictions on new data\n",
    "def predict_price_spread(model, new_data, X_scaler, y_scaler, time_steps=30):\n",
    "    \"\"\"\n",
    "    Make price_spread predictions on new data\n",
    "    \n",
    "    Args:\n",
    "        model: Trained LSTM model\n",
    "        new_data: New feature data (should have the same features as training data)\n",
    "        X_scaler: The scaler used to normalize the training features\n",
    "        y_scaler: The scaler used to normalize the target values\n",
    "        time_steps: Number of time steps used in the model\n",
    "        \n",
    "    Returns:\n",
    "        predictions: Predicted price_spread values\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Scale the new data\n",
    "    new_data_scaled = X_scaler.transform(new_data)\n",
    "    \n",
    "    # Create sequences for prediction\n",
    "    sequences = []\n",
    "    for i in range(len(new_data_scaled) - time_steps + 1):\n",
    "        sequences.append(new_data_scaled[i:i+time_steps])\n",
    "    \n",
    "    # Convert to tensor\n",
    "    sequences_tensor = torch.FloatTensor(sequences).to(device)\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        predicted_scaled = model(sequences_tensor).cpu().numpy()\n",
    "    \n",
    "    # Inverse transform the predictions\n",
    "    predictions = y_scaler.inverse_transform(predicted_scaled)\n",
    "    \n",
    "    return predictions.flatten()\n",
    "\n",
    "# Example of using the prediction function (assuming you have new data)\n",
    "# This would be applied to your test/validation data\n",
    "new_data = df[selected_features].values[-100:]  # Last 100 data points as an example\n",
    "predictions = predict_price_spread(trained_model, new_data, X_scaler, y_scaler)\n",
    "\n",
    "# # Plot the predictions\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(predictions, label='Predicted price_spread')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Price Spread')\n",
    "plt.title('Predicted Price Spread Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
